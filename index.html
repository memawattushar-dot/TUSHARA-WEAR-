<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TUSHARA-WEAR AI Assistant App</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styling for branding and scrollbar */
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f7f7f7;
        }
        .chat-container {
            max-height: calc(100vh - 200px); /* Adjust height for input, header, and image preview */
            overflow-y: auto;
            scroll-behavior: smooth;
        }
        /* Tushara Brand Colors */
        .brand-bg {
            background-color: #1e3a8a; /* Deep Blue */
        }
        .brand-text-accent {
            color: #f59e0b; /* Amber/Gold accent */
        }
        .brand-bg-accent {
            background-color: #f59e0b;
        }
        .user-message {
            background-color: #e5e7eb;
            color: #1f2937;
        }
        .ai-message {
            background-color: #1e3a8a;
            color: white;
        }
    </style>
    <!-- PWA Manifest and Theme Settings (Dynamically registered in JS) -->
    <meta name="theme-color" content="#1e3a8a">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
</head>
<body class="min-h-screen flex flex-col">

    <!-- Header -->
    <header class="brand-bg text-white p-4 shadow-lg sticky top-0 z-20">
        <h1 class="text-xl font-bold">TUSHARA-WEAR AI <span class="brand-text-accent">Assistant</span></h1>
        <p class="text-sm opacity-80">Ask any question or upload an image for style advice.</p>
    </header>

    <!-- Main Chat Display Area -->
    <main class="flex-grow p-4 md:p-6 pb-20">
        <div id="chat-container" class="chat-container space-y-4">
            <!-- Initial Welcome Message -->
            <div class="flex justify-start">
                <div class="ai-message p-3 rounded-xl rounded-tl-none max-w-xs md:max-w-md shadow-md flex items-start">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2 mt-0.5 brand-text-accent">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M9.813 15.904L9 18.75l-.813-2.846M4.5 18.75h15M17.25 4.5l-1.5 1.5L12 1.5 8.25 6l-1.5-1.5M4.5 9.75h15" />
                    </svg>
                    <div>
                        üëã <strong>Hello!</strong> I am the TUSHARA-WEAR AI Assistant. I can understand text and images. How can I help you today?
                        <button onclick="speakMessage(this)" class="ml-2 tts-button text-white hover:text-gray-300 transition duration-150 p-1 rounded-full absolute bottom-0 right-0">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-4 h-4">
                                <path fill-rule="evenodd" d="M9.383 3.076A1.25 1.25 0 0 0 8 4.01V15.99c0 .428.604.76 1.183.655l2.644-.529A3 3 0 0 1 15 13.012V6.988a3 3 0 0 1-3.173-2.476l-2.644-.53z" clip-rule="evenodd" />
                            </svg>
                        </button>
                    </div>
                </div>
            </div>
            <!-- Messages will be inserted here -->
        </div>
        
        <!-- Loading Indicator -->
        <div id="loading-indicator" class="hidden flex justify-start mt-4">
            <div class="p-3 bg-gray-200 rounded-xl rounded-tl-none max-w-xs md:max-w-md shadow-md">
                <div class="flex space-x-1">
                    <div class="w-2 h-2 bg-gray-500 rounded-full animate-bounce" style="animation-delay: -0.32s;"></div>
                    <div class="w-2 h-2 bg-gray-500 rounded-full animate-bounce" style="animation-delay: -0.16s;"></div>
                    <div class="w-2 h-2 bg-gray-500 rounded-full animate-bounce"></div>
                </div>
            </div>
        </div>
    </main>

    <!-- Input Area - Sticky Footer -->
    <div class="fixed bottom-0 left-0 w-full bg-white p-4 shadow-2xl z-20">
        <!-- Image Preview Area -->
        <div id="image-preview-container" class="hidden mb-3 p-2 bg-gray-100 rounded-lg max-w-4xl mx-auto border border-gray-300">
            <div class="flex items-center justify-between">
                <img id="image-preview" class="h-12 w-12 object-cover rounded mr-3" alt="Image Preview">
                <span class="text-sm text-gray-700 truncate" id="image-filename"></span>
                <button onclick="removeImage()" class="ml-3 text-red-500 hover:text-red-700 p-1 rounded-full">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5"><path d="M6.28 5.22a.75.75 0 0 0-1.06 1.06L8.94 10l-3.72 3.72a.75.75 0 1 0 1.06 1.06L10 11.06l3.72 3.72a.75.75 0 1 0 1.06-1.06L11.06 10l3.72-3.72a.75.75 0 0 0-1.06-1.06L10 8.94 6.28 5.22Z" /></svg>
                </button>
            </div>
        </div>
        
        <!-- Input Field and Buttons -->
        <div class="flex space-x-3 max-w-4xl mx-auto">
            
            <!-- Upload Image Button -->
            <label for="image-upload" class="brand-bg-accent text-white p-3 rounded-lg font-semibold shadow-md hover:bg-yellow-600 transition duration-150 flex items-center justify-center cursor-pointer disabled:opacity-50">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-5 h-5">
                    <path fill-rule="evenodd" d="M15.62 4.38a1.5 1.5 0 0 1 1.06 1.06l-.752 3.012a4 4 0 0 0-.25 1.137A4 4 0 0 0 16.948 15.66l.752 3.012a1.5 1.5 0 0 1-2.072 2.072l-3.012-.752A4 4 0 0 0 9.873 20a4 4 0 0 0-1.137-.25l-3.012.752a1.5 1.5 0 0 1-2.072-2.072l.752-3.012a4 4 0 0 0-.25-1.137A4 4 0 0 0 3.052 4.34l-.752-3.012a1.5 1.5 0 0 1 2.072-2.072l3.012.752A4 4 0 0 0 10.127 0a4 4 0 0 0 1.137.25l3.012-.752zM10 13a3 3 0 1 0 0-6 3 3 0 0 0 0 6z" clip-rule="evenodd" />
                </svg>
                <input type="file" id="image-upload" accept="image/*" class="hidden" onchange="previewImage(event)">
            </label>

            <input 
                type="text" 
                id="user-input" 
                placeholder="Type your question here (or upload an image)..." 
                class="flex-grow p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-[#f59e0b] focus:border-[#f59e0b]"
                onkeydown="if(event.key === 'Enter') document.getElementById('send-btn').click();"
            >
            <button 
                id="send-btn" 
                onclick="sendMessage()" 
                class="brand-bg-accent text-white p-3 rounded-lg font-semibold shadow-md hover:bg-yellow-600 transition duration-150 flex items-center justify-center disabled:opacity-50"
            >
                Send
            </button>
        </div>
        <p id="status-message" class="text-xs text-gray-500 mt-2 text-center hidden">AI Assistant is typing...</p>
    </div>

    <!-- JavaScript Logic: For AI, PWA, Chatting, TTS, and Image Upload -->
    <script>
        // --- 1. AI Configuration and State ---
        const API_KEY = ""; // Keep key empty, Canvas will provide it automatically
        const TEXT_MODEL = 'gemini-2.5-flash-preview-09-2025';
        const TTS_MODEL = 'gemini-2.5-flash-preview-tts';
        
        let chatHistory = [];
        let uploadedBase64Image = null; // Stores the base64 image data for the next message
        let audioContext = null;

        // DOM Elements
        const chatContainer = document.getElementById('chat-container');
        const userInput = document.getElementById('user-input');
        const sendButton = document.getElementById('send-btn');
        const loadingIndicator = document.getElementById('loading-indicator');
        const statusMessage = document.getElementById('status-message');
        const imageUpload = document.getElementById('image-upload');
        const imagePreviewContainer = document.getElementById('image-preview-container');
        const imagePreview = document.getElementById('image-preview');
        const imageFilename = document.getElementById('image-filename');
        
        // System instruction guides the model's persona and response style
        const systemInstruction = "Act as the expert customer service representative and fashion stylist for TUSHARA-WEAR. Provide concise, friendly, and helpful advice. When an image is provided, analyze the outfit and suggest matching TUSHARA-WEAR products or provide styling tips. Use Google Search to provide information on fashion trends, but always link it to men's clothing and style. Respond in English.";

        // --- Utility Functions ---

        /** Scrolls the chat container to the bottom. */
        function scrollToBottom() {
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        /** Converts basic Markdown in AI response to HTML for display. */
        function formatMarkdown(text) {
            // Bold (**text** or *text*)
            text = text.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
            text = text.replace(/\*(.*?)\*/g, '<strong>$1</strong>');
            // Newlines to breaks
            text = text.replace(/\n/g, '<br>');
            return text;
        }

        /** Creates and appends a message bubble to the chat container. */
        function appendMessage(role, content, sources = []) {
            const messageWrapper = document.createElement('div');
            messageWrapper.className = `flex ${role === 'user' ? 'justify-end' : 'justify-start'}`;

            const messageBubble = document.createElement('div');
            messageBubble.className = `p-3 rounded-xl max-w-xs md:max-w-md shadow-md transition-all duration-300 relative ${
                role === 'user' 
                    ? 'user-message rounded-br-none' 
                    : 'ai-message rounded-tl-none flex items-start'
            }`;

            // Add avatar icon for AI
            if (role !== 'user') {
                const icon = document.createElement('div');
                icon.innerHTML = `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-5 h-5 mr-2 mt-0.5 brand-text-accent"><path stroke-linecap="round" stroke-linejoin="round" d="M9.813 15.904L9 18.75l-.813-2.846M4.5 18.75h15M17.25 4.5l-1.5 1.5L12 1.5 8.25 6l-1.5-1.5M4.5 9.75h15" /></svg>`;
                messageBubble.appendChild(icon);
            }

            const contentDiv = document.createElement('div');
            contentDiv.className = 'flex-grow';

            if (content.image) {
                // Display uploaded image in chat
                const img = document.createElement('img');
                img.src = content.image;
                img.className = 'w-full h-auto rounded-lg mb-2 border border-gray-300 max-w-xs';
                contentDiv.appendChild(img);
            }

            // Display text
            const textContent = document.createElement('span');
            textContent.innerHTML = formatMarkdown(content.text);
            contentDiv.appendChild(textContent);

            messageBubble.appendChild(contentDiv);

            // Add TTS Button for AI responses
            if (role !== 'user') {
                const ttsButton = document.createElement('button');
                ttsButton.className = 'ml-2 tts-button text-white hover:text-gray-300 transition duration-150 p-1 rounded-full absolute bottom-1 right-1';
                ttsButton.innerHTML = `<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-4 h-4"><path fill-rule="evenodd" d="M9.383 3.076A1.25 1.25 0 0 0 8 4.01V15.99c0 .428.604.76 1.183.655l2.644-.529A3 3 0 0 1 15 13.012V6.988a3 3 0 0 1-3.173-2.476l-2.644-.53z" clip-rule="evenodd" /></svg>`;
                ttsButton.onclick = () => speakMessage(ttsButton, content.text);
                messageBubble.appendChild(ttsButton);
            }

            messageWrapper.appendChild(messageBubble);

            // Add sources below the message bubble for AI
            if (sources.length > 0 && role !== 'user') {
                const sourcesDiv = document.createElement('div');
                sourcesDiv.className = 'text-xs mt-1 p-2 bg-gray-100 rounded-lg border border-gray-200 text-black max-w-md';
                sourcesDiv.innerHTML = '<strong>üîç Sources:</strong><ul class="list-disc ml-4 mt-1 space-y-0.5">' + 
                    sources.map(s => `<li><a href="${s.uri}" target="_blank" class="text-blue-600 hover:underline">${s.title || s.uri}</a></li>`).join('') +
                    '</ul>';
                messageWrapper.appendChild(sourcesDiv);
            }

            chatContainer.appendChild(messageWrapper);
            scrollToBottom();
        }
        
        // --- 2. TTS (Text-to-Speech) Logic ---

        /** Converts Base64 string to ArrayBuffer. */
        function base64ToArrayBuffer(base64) {
            const binaryString = atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        /** Helper function to write string data to the WAV file. */
        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        /** Converts signed 16-bit PCM audio data to a WAV Blob. */
        function pcmToWav(pcm16, sampleRate) {
            const numChannels = 1;
            const bitsPerSample = 16;
            const byteRate = sampleRate * numChannels * (bitsPerSample / 8);
            const blockAlign = numChannels * (bitsPerSample / 8);
            const dataSize = pcm16.length * 2; // 16-bit PCM is 2 bytes per sample
            const buffer = new ArrayBuffer(44 + dataSize);
            const view = new DataView(buffer);
            let offset = 0;

            // RIFF chunk
            writeString(view, offset, 'RIFF'); offset += 4;
            view.setUint32(offset, 36 + dataSize, true); offset += 4;
            writeString(view, offset, 'WAVE'); offset += 4;

            // FMT chunk
            writeString(view, offset, 'fmt '); offset += 4;
            view.setUint32(offset, 16, true); offset += 4; // Sub-chunk size
            view.setUint16(offset, 1, true); offset += 2;  // Audio format (1 for PCM)
            view.setUint16(offset, numChannels, true); offset += 2;
            view.setUint32(offset, sampleRate, true); offset += 4;
            view.setUint32(offset, byteRate, true); offset += 4;
            view.setUint16(offset, blockAlign, true); offset += 2;
            view.setUint16(offset, bitsPerSample, true); offset += 2;

            // Data chunk
            writeString(view, offset, 'data'); offset += 4;
            view.setUint32(offset, dataSize, true); offset += 4;

            // Write the PCM data
            for (let i = 0; i < pcm16.length; i++) {
                view.setInt16(offset, pcm16[i], true);
                offset += 2;
            }

            return new Blob([buffer], { type: 'audio/wav' });
        }


        /** Fetches and plays the audio for a given text message. */
        async function speakMessage(button, text) {
            button.disabled = true;
            const originalIcon = button.innerHTML;
            button.innerHTML = `<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-4 h-4 animate-spin"><path fill-rule="evenodd" d="M15.31 9.5a1 1 0 0 1-1.37.74l-2.02-.4c-.5-.1-.8.43-.58.88l.99 1.98a1 1 0 0 1-1.68.84l-2.45-1.96a1 1 0 0 0-1.07-.06L4 12.5a1 1 0 0 1-1.68-.8l.75-1.5A1 1 0 0 0 2.27 9.5l-1.5-.75a1 1 0 0 1 0-1.77l1.5-.75a1 1 0 0 0 .5-.86l-.75-1.5a1 1 0 0 1 1.68-.84l2.45 1.96a1 1 0 0 0 1.07.06l2.02-.4c.5-.1.8.43.58.88l-.99 1.98a1 1 0 0 1 1.68.84l1.5-1.5a1 1 0 0 1 1.37.74zM10 12.5a2.5 2.5 0 1 0 0-5 2.5 2.5 0 0 0 0 5z" clip-rule="evenodd" /></svg>`;
            
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/${TTS_MODEL}:generateContent?key=${API_KEY}`;
            const payload = {
                contents: [{ parts: [{ text: text }] }],
                generationConfig: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        voiceConfig: {
                            // Using the 'Kore' voice as a firm, clear option
                            prebuiltVoiceConfig: { voiceName: "Kore" } 
                        }
                    }
                },
            };

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) throw new Error(`TTS API failed with status ${response.status}`);

                const result = await response.json();
                const part = result?.candidates?.[0]?.content?.parts?.[0];
                const audioData = part?.inlineData?.data;
                const mimeType = part?.inlineData?.mimeType;

                if (audioData && mimeType && mimeType.startsWith("audio/L16")) {
                    const sampleRateMatch = mimeType.match(/rate=(\d+)/);
                    const sampleRate = sampleRateMatch ? parseInt(sampleRateMatch[1], 10) : 16000;
                    
                    const pcmData = base64ToArrayBuffer(audioData);
                    const pcm16 = new Int16Array(pcmData);
                    
                    const wavBlob = pcmToWav(pcm16, sampleRate);
                    const audioUrl = URL.createObjectURL(wavBlob);
                    
                    const audio = new Audio(audioUrl);
                    audio.play().catch(e => console.error("Audio playback error:", e));

                    audio.onended = () => {
                        button.innerHTML = originalIcon;
                        button.disabled = false;
                        URL.revokeObjectURL(audioUrl); 
                    };

                } else {
                    console.error("TTS response missing valid audio data.");
                    alert('Sorry, the AI could not generate audio for this message.');
                }

            } catch (error) {
                console.error("TTS Error:", error);
                alert('An error occurred during Text-to-Speech generation.');
            } finally {
                if (!button.disabled) { // Only reset if audio failed before playback started
                    button.innerHTML = originalIcon;
                    button.disabled = false;
                }
            }
        }
        
        // --- 3. Image Handling (Visual Search) ---

        /** Displays image preview and converts it to Base64. */
        function previewImage(event) {
            const file = event.target.files[0];
            if (!file) {
                removeImage();
                return;
            }

            // Check file size (max 4MB for API)
            if (file.size > 4 * 1024 * 1024) {
                alert("Image size exceeds 4MB limit. Please choose a smaller image.");
                imageUpload.value = ''; // Reset file input
                removeImage();
                return;
            }

            const reader = new FileReader();
            reader.onload = (e) => {
                uploadedBase64Image = e.target.result.split(',')[1]; // Get only the base64 part
                
                imagePreview.src = e.target.result;
                imageFilename.textContent = file.name;
                imagePreviewContainer.classList.remove('hidden');
                scrollToBottom();
            };
            reader.readAsDataURL(file);
        }

        /** Removes the image preview and clears the base64 data. */
        function removeImage() {
            uploadedBase64Image = null;
            imageUpload.value = '';
            imagePreview.src = '';
            imageFilename.textContent = '';
            imagePreviewContainer.classList.add('hidden');
        }

        // --- 4. AI Interaction Core Logic ---

        /** Sends the user's message and optional image to the Gemini API. */
        async function fetchAIResponse(userQuery) {
            // 1. Build the content parts array
            const contentsParts = [];
            
            // Add image part if uploaded
            if (uploadedBase64Image) {
                contentsParts.push({
                    inlineData: {
                        mimeType: imageUpload.files[0].type,
                        data: uploadedBase64Image
                    }
                });
            }
            
            // Add text part
            contentsParts.push({ text: userQuery });
            
            // 2. Build the payload
            const payload = {
                contents: [{ parts: contentsParts }],
                tools: [{ "google_search": {} }], 
                systemInstruction: {
                    parts: [{ text: systemInstruction }]
                },
            };

            const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/${TEXT_MODEL}:generateContent?key=${API_KEY}`;
            let response;
            let result;
            let delay = 1000;
            const maxRetries = 3;

            // Exponential backoff for API calls
            for (let i = 0; i < maxRetries; i++) {
                try {
                    response = await fetch(API_URL, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });

                    if (response.status === 429) {
                        await new Promise(resolve => setTimeout(resolve, delay));
                        delay *= 2;
                        continue; 
                    }

                    if (!response.ok) {
                        throw new Error(`API returned status ${response.status}`);
                    }

                    result = await response.json();
                    break; 

                } catch (error) {
                    if (i === maxRetries - 1) {
                        throw new Error("Failed to receive response after multiple retries.");
                    }
                    await new Promise(resolve => setTimeout(resolve, delay));
                    delay *= 2;
                }
            }
            
            if (!result || !result.candidates || result.candidates.length === 0) {
                 throw new Error("Invalid response structure from API.");
            }

            const candidate = result.candidates[0];
            const text = candidate.content?.parts?.[0]?.text || "Sorry, I couldn't process that request.";

            let sources = [];
            const groundingMetadata = candidate.groundingMetadata;
            if (groundingMetadata && groundingMetadata.groundingAttributions) {
                sources = groundingMetadata.groundingAttributions
                    .map(attribution => ({
                        uri: attribution.web?.uri,
                        title: attribution.web?.title,
                    }))
                    .filter(source => source.uri); 
            }
            
            return { text, sources };
        }

        /** Handles sending the message and updating the UI. */
        async function sendMessage() {
            const query = userInput.value.trim();
            const hasImage = uploadedBase64Image !== null;

            if (!query && !hasImage) return;

            // 1. Prepare and show user message
            const userContent = { text: query };
            if (hasImage) {
                userContent.image = imagePreview.src;
            }
            appendMessage('user', userContent);
            
            // 2. Disable UI elements and show loading
            userInput.value = '';
            userInput.disabled = true;
            sendButton.disabled = true;
            statusMessage.classList.remove('hidden');
            loadingIndicator.classList.remove('hidden');
            
            // Important: Store image data and remove preview before API call
            const currentImage = uploadedBase64Image;
            const currentQuery = query;
            removeImage(); // Clears preview and base64 for next message
            scrollToBottom();

            try {
                // 3. Fetch AI response
                const { text, sources } = await fetchAIResponse(currentQuery);
                
                // 4. Update UI for AI response
                appendMessage('ai', { text: text }, sources);

            } catch (error) {
                console.error("Gemini API Error:", error);
                appendMessage('ai', { text: `<strong>Error:</strong> The AI encountered a problem: ${error.message}. Please try again.` });
            } finally {
                // 5. Reset UI
                userInput.disabled = false;
                sendButton.disabled = false;
                statusMessage.classList.add('hidden');
                loadingIndicator.classList.add('hidden');
                userInput.focus();
            }
        }

        // --- 5. PWA Setup (Dynamic Service Worker Registration) ---
        
        /** Defines the content of the Service Worker file. */
        function getServiceWorkerContent() {
            const CACHE_NAME = 'tushara-wear-cache-v3';
            // List of core files to cache for offline use
            const urlsToCache = [
                '/TUSHARA-WEAR/',
                '/TUSHARA-WEAR/index.html',
                'https://cdn.tailwindcss.com', 
            ];

            // Service Worker logic (Note: This is an inline definition)
            return `
                const CACHE_NAME = '${CACHE_NAME}';
                const urlsToCache = [${urlsToCache.map(url => `'${url}'`).join(', ')}];

                self.addEventListener('install', event => {
                    console.log('[Service Worker] Installing...');
                    event.waitUntil(
                        caches.open(CACHE_NAME)
                            .then(cache => cache.addAll(urlsToCache))
                            .catch(err => console.error('Cache addAll failed:', err))
                    );
                });

                self.addEventListener('fetch', event => {
                    event.respondWith(
                        caches.match(event.request).then(response => {
                            return response || fetch(event.request);
                        })
                    );
                });

                self.addEventListener('activate', event => {
                    const cacheWhitelist = [CACHE_NAME];
                    event.waitUntil(
                        caches.keys().then(cacheNames => {
                            return Promise.all(
                                cacheNames.map(cacheName => {
                                    if (cacheWhitelist.indexOf(cacheName) === -1) {
                                        return caches.delete(cacheName);
                                    }
                                })
                            );
                        })
                    );
                });
            `;
        }

        /** Dynamically registers the PWA Service Worker and Manifest. */
        function registerServiceWorker() {
            if ('serviceWorker' in navigator) {
                window.addEventListener('load', () => {
                    try {
                        // 1. Register Service Worker (using Blob for single file deployment)
                        const swContent = getServiceWorkerContent();
                        const swBlob = new Blob([swContent], { type: 'application/javascript' });
                        const swUrl = URL.createObjectURL(swBlob);

                        navigator.serviceWorker.register(swUrl, { scope: '/TUSHARA-WEAR/' })
                            .then(registration => console.log('PWA ServiceWorker registered successfully:', registration.scope))
                            .catch(error => console.error('PWA ServiceWorker registration failed:', error));
                        
                        // 2. Register Manifest
                        const manifest = {
                            "name": "TUSHARA-WEAR",
                            "short_name": "Tushara",
                            "description": "TUSHARA Menswear - AI Assistant PWA",
                            "start_url": "/TUSHARA-WEAR/",
                            "display": "standalone",
                            "background_color": "#ffffff",
                            "theme_color": "#1e3a8a",
                            "icons": [
                                // Using placeholder image URLs for icons
                                { "src": "https://placehold.co/192x192/1e3a8a/ffffff?text=T", "sizes": "192x192", "type": "image/png" },
                                { "src": "https://placehold.co/512x512/1e3a8a/ffffff?text=T", "sizes": "512x512", "type": "image/png" }
                            ]
                        };
                        const manifestBlob = new Blob([JSON.stringify(manifest)], { type: 'application/json' });
                        const manifestUrl = URL.createObjectURL(manifestBlob);
                        
                        const link = document.createElement('link');
                        link.rel = 'manifest';
                        link.href = manifestUrl;
                        document.head.appendChild(link);
                        
                    } catch (e) {
                        console.error("PWA Setup Error:", e);
                    }
                });
            }
        }

        // Initialize PWA on window load
        registerServiceWorker();
    </script>

</body>
</html>


